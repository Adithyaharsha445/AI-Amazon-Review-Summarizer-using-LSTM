{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b93e54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86150032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Define the trainable parameters: weights and bias for the attention mechanism\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=(input_shape[0][-1], input_shape[0][-1]),\n",
    "                                   initializer='glorot_uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=(input_shape[1][-1], input_shape[0][-1]),\n",
    "                                   initializer='glorot_uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=(input_shape[0][-1], 1),\n",
    "                                   initializer='glorot_uniform',\n",
    "                                   trainable=True)\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Inputs: [encoder_outputs, decoder_outputs]\n",
    "        encoder_outputs, decoder_outputs = inputs\n",
    "\n",
    "        # Compute the alignment scores\n",
    "        score = K.tanh(K.dot(encoder_outputs, self.W_a) + K.dot(decoder_outputs, self.U_a))\n",
    "        score = K.dot(score, self.V_a)\n",
    "        score = K.squeeze(score, axis=-1)  # Remove single-dimensional entries\n",
    "\n",
    "        # Compute the attention weights\n",
    "        attention_weights = K.softmax(score)\n",
    "\n",
    "        # Compute the context vector as a weighted sum of encoder outputs\n",
    "        context_vector = K.batch_dot(attention_weights, encoder_outputs, axes=[1, 1])\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [(input_shape[1][0], input_shape[1][1], input_shape[0][-1]),  # Context vector shape\n",
    "                (input_shape[1][0], input_shape[1][1])]  # Attention weights shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e66f3b",
   "metadata": {},
   "source": [
    "# Attention Layer Explanation\n",
    "\n",
    "The `attention.py` file defines an **Attention Layer** for neural networks, specifically for Sequence-to-Sequence (Seq2Seq) models. This layer improves the model's ability to focus on the most relevant parts of the input sequence during each decoding step, significantly enhancing the summarization process.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Functions of the Attention Layer**\n",
    "\n",
    "### **Purpose of Attention**\n",
    "- Attention allows the decoder to dynamically focus on specific parts of the encoder's outputs (contextual representations) while generating each word in the summary.\n",
    "- Instead of treating all encoder outputs equally, the decoder assigns **weights** (attention scores) to different encoder outputs based on their relevance to the current decoding step.\n",
    "\n",
    "---\n",
    "\n",
    "## **Code Breakdown**\n",
    "\n",
    "### 1. **`build(self, input_shape)`**\n",
    "- Initializes trainable weight matrices for the attention mechanism:\n",
    "  - **`W_a`**: Transforms encoder outputs into a comparable space with decoder outputs.\n",
    "  - **`U_a`**: Transforms decoder outputs to align with transformed encoder outputs.\n",
    "  - **`V_a`**: Projects the combined alignment scores into a single scalar for each encoder time step.\n",
    "- Uses the `glorot_uniform` initializer to ensure optimal weight initialization for better gradient flow.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **`call(self, inputs)`**\n",
    "Processes the inputs to calculate attention weights and context vectors:\n",
    "\n",
    "- **Inputs**: \n",
    "  - `encoder_outputs`: Sequence of outputs from the encoder (hidden states across all time steps).\n",
    "  - `decoder_outputs`: Current hidden state of the decoder.\n",
    "\n",
    "- **Steps**:\n",
    "  1. **Compute Alignment Scores**:\n",
    "     \\[\n",
    "     \\text{score} = \\tanh(W_a \\cdot \\text{encoder\\_outputs} + U_a \\cdot \\text{decoder\\_outputs})\n",
    "     \\]\n",
    "     Captures the similarity between the encoder outputs and the decoder state.\n",
    "     \n",
    "  2. **Apply Scoring Weights**:\n",
    "     \\[\n",
    "     \\text{score} = V_a \\cdot \\text{score}\n",
    "     \\]\n",
    "     Reduces the scores to a scalar for each encoder time step.\n",
    "\n",
    "  3. **Compute Attention Weights**:\n",
    "     \\[\n",
    "     \\text{attention\\_weights} = \\text{softmax(score)}\n",
    "     \\]\n",
    "     Converts the scores into probabilities, representing the importance of each encoder time step.\n",
    "\n",
    "  4. **Compute Context Vector**:\n",
    "     \\[\n",
    "     \\text{context\\_vector} = \\text{sum}(\\text{attention\\_weights} \\cdot \\text{encoder\\_outputs})\n",
    "     \\]\n",
    "     Generates a weighted sum of encoder outputs, focusing on the most relevant parts.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **`compute_output_shape(self, input_shape)`**\n",
    "Defines the output shapes:\n",
    "- **Context Vector**: Combines encoder outputs dynamically based on attention weights.\n",
    "- **Attention Weights**: Probabilities representing the importance of each encoder time step.\n",
    "\n",
    "---\n",
    "\n",
    "## **How Attention Enhances the Model**\n",
    "\n",
    "1. **Dynamic Focus**:\n",
    "   - Attention enables the model to selectively prioritize specific encoder outputs during decoding, rather than processing all inputs uniformly.\n",
    "\n",
    "2. **Improved Contextual Understanding**:\n",
    "   - Helps capture dependencies between input and output sequences, particularly for long texts, where fixed-length representations may lose critical information.\n",
    "\n",
    "3. **Better Summarization**:\n",
    "   - By focusing on the most relevant parts of the input, the model generates more accurate and contextually appropriate summaries.\n",
    "\n",
    "4. **Interpretability**:\n",
    "   - The attention weights show which parts of the input contributed to the output, making the model's decisions more transparent.\n",
    "\n",
    "---\n",
    "\n",
    "## **In Summary**\n",
    "The `AttentionLayer` enhances the Seq2Seq model by introducing a mechanism that dynamically prioritizes certain encoder outputs during decoding. This improves performance on complex sequences and allows the model to produce high-quality summaries by focusing on the most relevant context. The layer also adds interpretability to the model's predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d11a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
